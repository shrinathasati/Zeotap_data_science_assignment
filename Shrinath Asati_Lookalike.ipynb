{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 2: Lookalike Model**"
      ],
      "metadata": {
        "id": "F-h-V1G_Lb_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "IcIiMV0yqtC8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and merge datasets\n",
        "def load_and_merge_data():\n",
        "    \"\"\"Load customer, product, and transaction data, and merge them.\"\"\"\n",
        "    # Load datasets\n",
        "    customers = pd.read_csv('Customers.csv')\n",
        "    products = pd.read_csv('Products.csv')\n",
        "    transactions = pd.read_csv('Transactions.csv')\n",
        "\n",
        "    # Merge datasets on relevant keys\n",
        "    transactions = transactions.merge(customers, on='CustomerID', how='left')\n",
        "    transactions = transactions.merge(products, on='ProductID', how='left')\n",
        "\n",
        "    return transactions, customers"
      ],
      "metadata": {
        "id": "UYNV5e907nUe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform feature engineering and generate customer profiles\n",
        "def create_customer_profiles(transactions, customers):\n",
        "    \"\"\"Feature engineering: Aggregate transaction data and create customer profiles.\"\"\"\n",
        "    # Aggregate transaction data for customer profiles\n",
        "    customer_profiles = transactions.groupby('CustomerID').agg(\n",
        "        TotalSpending=('TotalValue', 'sum'),\n",
        "        TransactionCount=('TransactionID', 'count'),\n",
        "        AvgTransactionValue=('TotalValue', 'mean'),\n",
        "        AvgQuantity=('Quantity', 'mean'),\n",
        "        DaysSinceLastPurchase=('TransactionDate', lambda x: (datetime.now() - pd.to_datetime(x)).dt.days.min())\n",
        "    ).reset_index()\n",
        "\n",
        "    # Add product category preferences as additional features\n",
        "    category_pref = transactions.groupby(['CustomerID', 'Category']).agg(Spending=('TotalValue', 'sum')).unstack(fill_value=0)\n",
        "    category_pref.columns = [f'Category_{col[1]}_Spending' for col in category_pref.columns]\n",
        "    customer_profiles = customer_profiles.merge(category_pref, on='CustomerID', how='left')\n",
        "\n",
        "    # Add region and signup date to profiles\n",
        "    customer_profiles = customer_profiles.merge(\n",
        "        customers[['CustomerID', 'Region', 'SignupDate']],\n",
        "        on='CustomerID',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # One-hot encode categorical features like 'Region'\n",
        "    customer_profiles = pd.get_dummies(customer_profiles, columns=['Region'], drop_first=True)\n",
        "\n",
        "    return customer_profiles\n"
      ],
      "metadata": {
        "id": "Az1eIQOq7LZT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to normalize and scale the customer profile features\n",
        "def normalize_features(customer_profiles):\n",
        "    \"\"\"Normalize the customer profile features.\"\"\"\n",
        "    # Exclude non-numeric columns\n",
        "    features = customer_profiles.drop(columns=['CustomerID', 'SignupDate'])\n",
        "\n",
        "    # Normalize features using StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    normalized_features = scaler.fit_transform(features)\n",
        "\n",
        "    return normalized_features, features"
      ],
      "metadata": {
        "id": "jhqwQBUI7uBP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform KMeans clustering\n",
        "def perform_clustering(normalized_features, num_clusters=5):\n",
        "    \"\"\"Perform KMeans clustering to segment customers into groups.\"\"\"\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "    cluster_labels = kmeans.fit_predict(normalized_features)\n",
        "\n",
        "    return cluster_labels, kmeans"
      ],
      "metadata": {
        "id": "SS164Fqa70N9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate similarity scores within clusters\n",
        "def calculate_similarity(customer_profiles, normalized_features, cluster_labels):\n",
        "    \"\"\"Calculate similarity scores for customers within each cluster.\"\"\"\n",
        "    similarity_results = {}\n",
        "\n",
        "    for cluster in np.unique(cluster_labels):\n",
        "        cluster_data = customer_profiles[customer_profiles['Cluster'] == cluster]\n",
        "        cluster_ids = cluster_data['CustomerID'].values\n",
        "        cluster_features = normalized_features[cluster_labels == cluster]\n",
        "\n",
        "        # Calculate cosine similarity within the cluster\n",
        "        similarity_matrix = cosine_similarity(cluster_features)\n",
        "\n",
        "        for idx, customer_id in enumerate(cluster_ids):\n",
        "            sim_scores = list(enumerate(similarity_matrix[idx]))\n",
        "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "            top_3 = sim_scores[1:4]  # Get top 3 lookalikes\n",
        "            similarity_results[customer_id] = [\n",
        "                (cluster_ids[i], round(score, 4)) for i, score in top_3\n",
        "            ]\n",
        "\n",
        "    return similarity_results\n"
      ],
      "metadata": {
        "id": "7d3u3d8375dA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate the Lookalike.csv file\n",
        "def generate_lookalike_csv(similarity_results):\n",
        "    \"\"\"Generate Lookalike.csv with customer similarities.\"\"\"\n",
        "    lookalike_data = [\n",
        "        {'CustomerID': customer_id, 'Lookalikes': lookalikes}\n",
        "        for customer_id, lookalikes in similarity_results.items()\n",
        "    ]\n",
        "\n",
        "    lookalike_df = pd.DataFrame(lookalike_data)\n",
        "    lookalike_df.to_csv('Shrinath_Asati_Lookalike.csv', index=False)\n",
        "\n",
        "    return lookalike_df"
      ],
      "metadata": {
        "id": "TgKEYrNx78ug"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function\n",
        "def main():\n",
        "    # Load and merge data\n",
        "    transactions, customers = load_and_merge_data()\n",
        "\n",
        "    # Create customer profiles with aggregated features\n",
        "    customer_profiles = create_customer_profiles(transactions, customers)\n",
        "\n",
        "    # Normalize features for clustering\n",
        "    normalized_features, features = normalize_features(customer_profiles)\n",
        "\n",
        "    # Perform clustering\n",
        "    cluster_labels, kmeans = perform_clustering(normalized_features)\n",
        "\n",
        "    # Add cluster labels to customer profiles\n",
        "    customer_profiles['Cluster'] = cluster_labels\n",
        "\n",
        "    # Calculate similarity scores within clusters\n",
        "    similarity_results = calculate_similarity(customer_profiles, normalized_features, cluster_labels)\n",
        "\n",
        "    # Generate Lookalike.csv and display the results for the first 20 customers\n",
        "    lookalike_df = generate_lookalike_csv(similarity_results)\n",
        "    print(lookalike_df[lookalike_df['CustomerID'].isin([f'C{i:04d}' for i in range(1, 21)])])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQpNqM388BwV",
        "outputId": "d56dd9e6-630d-4674-c597-b799bfd576fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    CustomerID                                         Lookalikes\n",
            "0        C0004  [(C0113, 0.8769), (C0012, 0.8374), (C0104, 0.8...\n",
            "1        C0006  [(C0169, 0.7878), (C0153, 0.6957), (C0082, 0.6...\n",
            "2        C0012  [(C0113, 0.903), (C0104, 0.8887), (C0163, 0.86...\n",
            "3        C0013  [(C0099, 0.9512), (C0188, 0.9026), (C0165, 0.7...\n",
            "47       C0001  [(C0181, 0.8495), (C0120, 0.7808), (C0091, 0.7...\n",
            "48       C0002  [(C0159, 0.8754), (C0106, 0.8588), (C0178, 0.8...\n",
            "49       C0003  [(C0091, 0.8063), (C0120, 0.7556), (C0129, 0.7...\n",
            "50       C0005  [(C0123, 0.8356), (C0186, 0.821), (C0140, 0.80...\n",
            "51       C0007  [(C0140, 0.7812), (C0005, 0.7771), (C0123, 0.5...\n",
            "52       C0011  [(C0107, 0.7482), (C0190, 0.7382), (C0191, 0.7...\n",
            "105      C0014  [(C0097, 0.8422), (C0128, 0.8252), (C0060, 0.7...\n",
            "106      C0020  [(C0080, 0.8264), (C0110, 0.8176), (C0144, 0.8...\n",
            "119      C0009  [(C0198, 0.9508), (C0119, 0.923), (C0121, 0.87...\n",
            "120      C0010  [(C0111, 0.9709), (C0132, 0.8978), (C0062, 0.7...\n",
            "121      C0017  [(C0179, 0.8376), (C0057, 0.8263), (C0051, 0.8...\n",
            "122      C0019  [(C0119, 0.8841), (C0121, 0.8425), (C0009, 0.7...\n",
            "162      C0008  [(C0098, 0.8703), (C0194, 0.8362), (C0024, 0.8...\n",
            "163      C0015  [(C0036, 0.8454), (C0094, 0.8112), (C0035, 0.8...\n",
            "164      C0016  [(C0042, 0.7378), (C0183, 0.7285), (C0024, 0.6...\n",
            "165      C0018  [(C0026, 0.7766), (C0125, 0.7305), (C0050, 0.7...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogtm5nhw8e8S"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}